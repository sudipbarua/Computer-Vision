{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover the Homography with DLT with of Noise (Exact Sulution)\n",
    "\n",
    "A 2D canvas shows two houses. One house is generated by applying a projetivity on the other house.\n",
    "AFTER the transformation, both houses suffer from noise artifacts.\n",
    "Please try to determine the exact homography matrix.\n",
    "  \n",
    "Hint: Please make sure that you have installed Scipy. You can do that by entering\n",
    "`python.exe -m pip install --user scipy`\n",
    "on the CMD or Powershell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not learn imports by hard for the exam in general. This is not important.\n",
    "import numpy as np\n",
    "\n",
    "# use the following 2-by-11 matrix to define a simple house\n",
    "X_inhom = np.array([\n",
    "    [-6, -6, -7, 0, 7, 6,  6, -3, -3,  0,  0],\n",
    "    [-7,  2,  1, 8, 1, 2, -7, -7, -2, -2, -7]\n",
    "], dtype=np.float)\n",
    "\n",
    "# make points homogeneous\n",
    "num_pts = X_inhom.shape[1]\n",
    "X = np.concatenate([X_inhom, np.ones((1, num_pts))])\n",
    "\n",
    "# This time, we take all points! No subset!\n",
    "num_pts_sel = num_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define and apply a homography that should be recovered later on.\n",
    "Euclidean transformations are a subset of affinities and affinities are a subset of projectivities.\n",
    "Let's use a simple rotation as our homography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D rotation homogeneous space\n",
    "alpha = 45 * np.pi / 180 # 45 degrees\n",
    "\n",
    "H = np.array([\n",
    "    [np.cos(alpha), -np.sin(alpha), 0],\n",
    "    [np.sin(alpha),  np.cos(alpha), 0],\n",
    "    [0,           0,          1]\n",
    "], dtype=np.float)\n",
    "\n",
    "X2 = H.dot(X)\n",
    "\n",
    "# Now make original point set and transformed point set noisy.\n",
    "# We can do that by adding \"noice matrices\" with gaussian distributed offset values.\n",
    "# One noice matrix for each!\n",
    "stddev = 0.1 # increase stddev to increase the noise\n",
    "\n",
    "X_noise = np.random.normal(scale=stddev, size=X.shape)\n",
    "X = X + X_noise\n",
    "X2_noise = np.random.normal(scale=stddev, size=X2.shape)\n",
    "X2 = X2 + X2_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, we only need 4 point correspondences if there is no noise. We have already made a selection of 4 points by defining the python list `subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel  =  X # select all points\n",
    "X2_sel = X2 # select all points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the DLT linear equation system of the lecture:  \n",
    "$\\begin{pmatrix}\n",
    "    \\mathbf{0}^T & -w'_i\\mathbf{x}^T_i & y'_i\\mathbf{x}^T_i \\\\\n",
    "    w'_i\\mathbf{x}^T_i & \\mathbf{0}^T & -x'_i\\mathbf{x}^T_i \\\\\n",
    "\\end{pmatrix} \\cdot\n",
    "\\begin{pmatrix}\n",
    "    \\mathbf{h}_{\\text{r}1} \\\\ \\mathbf{h}_{\\text{r}2} \\\\ \\mathbf{h}_{\\text{r}3}\n",
    "\\end{pmatrix}\n",
    "= \\mathbf{0}$  \n",
    "  \n",
    "$ \\mathbf{A}_i \\cdot \\mathbf{h} = \\mathbf{0} $\n",
    "\n",
    "  \n",
    "Whereas $\\mathbf{x}_i$ is the $i$-th point in the point array `X_sel` and \n",
    "$\\mathbf{x}'_i = \\begin{pmatrix} x'_i \\\\ y'_i \\\\ w'_i \\end{pmatrix}$ is the projectively transformed $i$-th point in the point array `X2_sel`.  \n",
    "$\\mathbf{h}_{\\text{r}i}$ is `H[i,:].T`, the transposed $i$-th row of the homography $\\mathbf{H}$.\n",
    "  \n",
    "For 4 point correspondences, $\\mathbf{A}$ is the concatenation of all $\\mathbf{A}_i \\text{ for } i \\in \\{1,2,3,4\\}$.\n",
    "You might want to reorganize the order of colums (wihtout loss of generality):  \n",
    "$\\begin{pmatrix}\n",
    "    \\mathbf{0}^T & -w'_1\\mathbf{x}^T_1 & y'_1\\mathbf{x}^T_1 \\\\\n",
    "    \\mathbf{0}^T & -w'_2\\mathbf{x}^T_2 & y'_2\\mathbf{x}^T_2 \\\\\n",
    "    \\mathbf{0}^T & -w'_3\\mathbf{x}^T_3 & y'_3\\mathbf{x}^T_3 \\\\\n",
    "    \\mathbf{0}^T & -w'_4\\mathbf{x}^T_4 & y'_4\\mathbf{x}^T_4 \\\\\n",
    "    w'_1\\mathbf{x}^T_1 & \\mathbf{0}^T & -x'_1\\mathbf{x}^T_1 \\\\\n",
    "    w'_2\\mathbf{x}^T_2 & \\mathbf{0}^T & -x'_2\\mathbf{x}^T_2 \\\\\n",
    "    w'_3\\mathbf{x}^T_3 & \\mathbf{0}^T & -x'_3\\mathbf{x}^T_3 \\\\\n",
    "    w'_4\\mathbf{x}^T_4 & \\mathbf{0}^T & -x'_4\\mathbf{x}^T_4 \\\\\n",
    "\\end{pmatrix} \\cdot\n",
    "\\begin{pmatrix}\n",
    "    \\mathbf{h}_{\\text{r}1} \\\\ \\mathbf{h}_{\\text{r}2} \\\\ \\mathbf{h}_{\\text{r}3}\n",
    "\\end{pmatrix}\n",
    "= \\mathbf{0}$  \n",
    "  \n",
    "$ \\begin{pmatrix}\n",
    "    \\mathbf{A}_\\text{top} \\\\ \\mathbf{A}_\\text{bottom}\n",
    "\\end{pmatrix}\n",
    "\\cdot \\mathbf{h} = \\mathbf{0} $  \n",
    "  \n",
    "$ \\mathbf{A} \\cdot \\mathbf{h} = \\mathbf{0} $\n",
    "  \n",
    "Now, consider the first 4 rows of $\\mathbf{A}$ being `A_top` and the last 4 rows of $\\mathbf{A}$ being `A_bottom`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x' is:  (11,)\n"
     ]
    }
   ],
   "source": [
    "x_trans = X2_sel[0,:]\n",
    "y_trans = X2_sel[1,:]\n",
    "w_trans = X2_sel[2,:]\n",
    "print(\"shape of x' is: \", x_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x' is:  (11, 1)\n"
     ]
    }
   ],
   "source": [
    "# We need (4,1) not (4,).\n",
    "# Sometimes numpy squeezes dimensions. Let's undo this:\n",
    "x_trans = np.expand_dims(x_trans, axis=1)\n",
    "y_trans = np.expand_dims(y_trans, axis=1)\n",
    "w_trans = np.expand_dims(w_trans, axis=1)\n",
    "print(\"shape of x' is: \", x_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of A_top is: (11, 9)\n",
      "shape of A_bottom is: (11, 9)\n",
      "shape of A is: (22, 9)\n"
     ]
    }
   ],
   "source": [
    "row_1234_col_123 = np.zeros((num_pts_sel, 3), dtype=np.float)\n",
    "row_1234_col_456 = -w_trans * X_sel.T\n",
    "row_1234_col_789 =  y_trans * X_sel.T\n",
    "\n",
    "# np.vstack(...) is equivalent to np.concatenate(..., axis=0) and means stack vertically\n",
    "# np.hstack(...) is equivalent to np.concatenate(..., axis=1) and means stack horizontally\n",
    "\n",
    "A_top = np.hstack([row_1234_col_123, row_1234_col_456, row_1234_col_789])\n",
    "print(\"shape of A_top is:\", A_top.shape)\n",
    "\n",
    "row_5678_col_123 = w_trans * X_sel.T\n",
    "row_5678_col_456 = np.zeros((num_pts_sel, 3), dtype=np.float)\n",
    "row_5678_col_789 = -x_trans * X_sel.T\n",
    "\n",
    "A_bottom = np.hstack([row_5678_col_123, row_5678_col_456, row_5678_col_789])\n",
    "print(\"shape of A_bottom is:\", A_bottom.shape)\n",
    "\n",
    "A = np.vstack([A_top, A_bottom])\n",
    "print(\"shape of A is:\", A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\mathbf{A} \\cdot \\mathbf{h} \\neq \\mathbf{0}$, we cannot simply take the right null space of $\\mathbf{A}$ but we can decompose $\\mathbf{A}$:  \n",
    "  \n",
    "$\\mathbf{A} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T$  \n",
    "  \n",
    "Then, the *best* $\\mathbf{h}$ is the unit singular vector $\\mathbf{v}_{\\text{r}}$ belonging to the smallest singular value $\\mathbf{\\sigma}_r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank of DLT system matrix is: 9\n",
      "[ 0.42730904 -0.37914407  0.07882605  0.43516074  0.38959701  0.1136227\n",
      "  0.00120771  0.00058     0.55980407]\n",
      "The reconstructed homography is:\n",
      "[[ 0.76331891 -0.67727993  0.14081007]\n",
      " [ 0.77734473  0.69595244  0.2029687 ]\n",
      " [ 0.00215739  0.00103607  1.        ]]\n",
      "1.7863392716101627\n"
     ]
    }
   ],
   "source": [
    "U, S, VT = np.linalg.svd(A)\n",
    "r = np.linalg.matrix_rank(A)\n",
    "\n",
    "print(\"rank of DLT system matrix is:\", r)\n",
    "h = VT[r-1, :] # subtract 1 because we start indexing with 0\n",
    "# VT[r-1, :] is the same as V[:, r-1], the r-th colum vector of V\n",
    "print(h)\n",
    "h = h / h[8]\n",
    "\n",
    "H_r = h.reshape((3, 3)) # from vector back to matrix\n",
    "H_r = H_r / H_r[-1, -1] # divide by last row and last collumn to normalize the homography. Now, H[3, 3] should be 1\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"The reconstructed homography is:\")\n",
    "print(H_r)\n",
    "print(np.linalg.norm(H_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the reconstruction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residuum: [[-0.05621213 -0.02982685 -0.14081007]\n",
      " [-0.07023795  0.01115434 -0.2029687 ]\n",
      " [-0.00215739 -0.00103607  0.        ]]\n",
      "MAE: 0.05715594280120438\n"
     ]
    }
   ],
   "source": [
    "# calculate the MAE (mean absolute error)\n",
    "residuum = H - H_r\n",
    "print(\"residuum:\", residuum)\n",
    "abs_error = np.abs(residuum)\n",
    "mae = np.mean(abs_error)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
